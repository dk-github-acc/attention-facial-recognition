{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "ImageShape = Tuple[int, int]\n",
    "GrayScaleImageShape = Tuple[int, int, int]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Sandbox Baseline Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is (60000, 28, 28)\n",
      "The shape of y_train is (60000,)\n",
      "The shape of X_test is (10000, 28, 28)\n",
      "The shape of y_test is (10000,) - some example targets: [7 2 1 0 4]\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "Dataset = Tuple[np.ndarray, np.ndarray]\n",
    "\n",
    "#download mnist data and split into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(f\"The shape of X_train is {X_train.shape}\")\n",
    "print(f\"The shape of y_train is {y_train.shape}\")\n",
    "print(f\"The shape of X_test is {X_test.shape}\")\n",
    "print(f\"The shape of y_test is {y_test.shape} - some example targets: {y_test[:5]}\")\n",
    "mnist_image_shape: ImageShape = X_train.shape[1:]\n",
    "print(mnist_image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoding y_train (60000,) -> (60000, 10)\n",
      "One-hot encoding y_test (10000,) -> (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "OneHotEncodedTarget = np.ndarray\n",
    "Categories = int\n",
    "encoded_y_train: OneHotEncodedTarget = to_categorical(y_train)\n",
    "encoded_y_test: OneHotEncodedTarget = to_categorical(y_test)\n",
    "print(f\"One-hot encoding y_train {y_train.shape} -> {encoded_y_train.shape}\")\n",
    "print(f\"One-hot encoding y_test {y_test.shape} -> {encoded_y_test.shape}\")\n",
    "\n",
    "K: Categories = encoded_y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla CNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_3/Softmax:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, Input\n",
    "from tensorflow.python.framework.ops import Tensor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# define model architecture and hyperparameters\n",
    "NUM_FILTERS_L1 = 64\n",
    "NUM_FILTERS_L2 = 32\n",
    "KERNEL_SIZE = 3\n",
    "\n",
    "# the images are 28 x 28 (pixel size) x 1 (grayscale - if RGB, then 3)\n",
    "input_dims: GrayScaleImageShape = (28,28,1)\n",
    "\n",
    "def build_vanilla_cnn(filters_layer1:int, filters_layer2:int, kernel_size:int, input_dims: GrayScaleImageShape)-> Model:\n",
    "    inputs: Tensor = Input(shape=input_dims)\n",
    "    x: Tensor = Conv2D(filters=filters_layer1, kernel_size=kernel_size, activation='relu')(inputs)\n",
    "    x: Tensor = Conv2D(filters=filters_layer2, kernel_size=kernel_size, activation='relu')(x)\n",
    "    x: Tensor = Flatten()(x)\n",
    "    predictions = Dense(K, activation=\"softmax\")(x)\n",
    "    print(predictions)\n",
    "\n",
    "    #compile model using accuracy to measure model performance\n",
    "    model: Model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model: Model = build_vanilla_cnn(NUM_FILTERS_L1, NUM_FILTERS_L2, KERNEL_SIZE, input_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding shape from (60000, 28, 28) to (60000, 28, 28, 1)\n",
      "Expanding shape from (10000, 28, 28) to (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train.reshape((60000,1,28,28))\n",
    "\n",
    "def expand_tensor_shape(X_train: np.ndarray)-> np.ndarray:\n",
    "    new_shape: Tuple = X_train.shape + (1,)\n",
    "        \n",
    "#     new_tensor = X_train.reshape(new_shape).reshape((-1,1,28,28))\n",
    "    new_tensor = X_train.reshape(new_shape)\n",
    "    print(f\"Expanding shape from {X_train.shape} to {new_tensor.shape}\")\n",
    "    return new_tensor\n",
    "\n",
    "X_train_expanded: np.ndarray = expand_tensor_shape(X_train)\n",
    "X_test_expanded: np.ndarray = expand_tensor_shape(X_test)\n",
    "    \n",
    "    \n",
    "# train model and retrieve history\n",
    "# from keras.callbacks import History\n",
    "# history: History = model.fit(X_train_expanded, encoded_y_train, \n",
    "#                              validation_data=(X_test_expanded, encoded_y_test), epochs=2, batch_size=2058)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Average Pooling Layer\n",
    "\n",
    "Output shape of convolutional layer is typically `batch size x number of filters x width x height`. The GAP layer will take the average of the width/height axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(X_train_expanded, (-1,1,28,28)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer, Lambda\n",
    "def global_average_pooling(x: Layer):\n",
    "    return K.mean(x, axis = (2,3))\n",
    "\n",
    "def global_average_pooling_shape(input_shape):\n",
    "    # return only the first two dimensions (batch size and number of filters)\n",
    "    return input_shape[0:2]\n",
    "\n",
    "def build_global_average_pooling_layer(function, output_shape):\n",
    "    return Lambda(pooling_function, output_shape)\n",
    "\n",
    "\n",
    "def get_output_layer(model, layer_name):\n",
    "    # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "    layer = layer_dict[layer_name]\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "lambda_12 (Lambda)           (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 61,706.0\n",
      "Trainable params: 61,706.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 18s - loss: 9.5367 - acc: 0.1422 - val_loss: 8.4200 - val_acc: 0.2723\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 23s - loss: 7.0761 - acc: 0.2683 - val_loss: 5.7630 - val_acc: 0.2534\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 25s - loss: 4.8567 - acc: 0.3148 - val_loss: 4.3812 - val_acc: 0.3265\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 24s - loss: 3.2996 - acc: 0.3603 - val_loss: 2.0068 - val_acc: 0.3007\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 22s - loss: 1.7840 - acc: 0.4184 - val_loss: 1.5537 - val_acc: 0.5266\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 18s - loss: 1.3758 - acc: 0.5662 - val_loss: 1.0899 - val_acc: 0.7001\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 20s - loss: 0.9062 - acc: 0.7501 - val_loss: 0.6418 - val_acc: 0.8260\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 24s - loss: 0.5201 - acc: 0.8572 - val_loss: 0.3620 - val_acc: 0.8995\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 23s - loss: 0.3182 - acc: 0.9088 - val_loss: 0.2445 - val_acc: 0.9293\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 22s - loss: 0.2384 - acc: 0.9293 - val_loss: 0.1950 - val_acc: 0.9445\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 22s - loss: 0.1973 - acc: 0.9421 - val_loss: 0.1627 - val_acc: 0.9517\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 20s - loss: 0.1684 - acc: 0.9505 - val_loss: 0.1436 - val_acc: 0.9570\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 22s - loss: 0.1503 - acc: 0.9557 - val_loss: 0.1266 - val_acc: 0.9636\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 25s - loss: 0.1399 - acc: 0.9587 - val_loss: 0.1289 - val_acc: 0.9594\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.1279 - acc: 0.9621 - val_loss: 0.1104 - val_acc: 0.9664\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 23s - loss: 0.1166 - acc: 0.9655 - val_loss: 0.1032 - val_acc: 0.9690\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.1089 - acc: 0.9670 - val_loss: 0.0979 - val_acc: 0.9718\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 20s - loss: 0.1016 - acc: 0.9693 - val_loss: 0.0908 - val_acc: 0.9721\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0957 - acc: 0.9718 - val_loss: 0.0905 - val_acc: 0.9721\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0913 - acc: 0.9724 - val_loss: 0.0856 - val_acc: 0.9750\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0874 - acc: 0.9740 - val_loss: 0.0816 - val_acc: 0.9764\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0842 - acc: 0.9752 - val_loss: 0.0833 - val_acc: 0.9734\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0811 - acc: 0.9759 - val_loss: 0.0813 - val_acc: 0.9764\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0782 - acc: 0.9772 - val_loss: 0.0766 - val_acc: 0.9767\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0740 - acc: 0.9781 - val_loss: 0.0708 - val_acc: 0.9790\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 20s - loss: 0.0701 - acc: 0.9786 - val_loss: 0.0681 - val_acc: 0.9795\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 21s - loss: 0.0683 - acc: 0.9798 - val_loss: 0.0697 - val_acc: 0.9775\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 20s - loss: 0.0681 - acc: 0.9796 - val_loss: 0.0659 - val_acc: 0.9799\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 22s - loss: 0.0671 - acc: 0.9798 - val_loss: 0.0666 - val_acc: 0.9805\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0631 - acc: 0.9809 - val_loss: 0.0620 - val_acc: 0.9809\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 20s - loss: 0.0601 - acc: 0.9819 - val_loss: 0.0609 - val_acc: 0.9815\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 20s - loss: 0.0589 - acc: 0.9822 - val_loss: 0.0591 - val_acc: 0.9822\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0567 - acc: 0.9831 - val_loss: 0.0590 - val_acc: 0.9818\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0549 - acc: 0.9836 - val_loss: 0.0576 - val_acc: 0.9829\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0562 - acc: 0.9830 - val_loss: 0.0575 - val_acc: 0.9823\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0538 - acc: 0.9836 - val_loss: 0.0605 - val_acc: 0.9802\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0519 - acc: 0.9841 - val_loss: 0.0560 - val_acc: 0.9823\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0499 - acc: 0.9851 - val_loss: 0.0536 - val_acc: 0.9830\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0494 - acc: 0.9857 - val_loss: 0.0551 - val_acc: 0.9827\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0489 - acc: 0.9854 - val_loss: 0.0584 - val_acc: 0.9812\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0492 - acc: 0.9851 - val_loss: 0.0556 - val_acc: 0.9829\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0468 - acc: 0.9861 - val_loss: 0.0486 - val_acc: 0.9840\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0436 - acc: 0.9871 - val_loss: 0.0466 - val_acc: 0.9850\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0432 - acc: 0.9870 - val_loss: 0.0486 - val_acc: 0.9848\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 21s - loss: 0.0417 - acc: 0.9877 - val_loss: 0.0490 - val_acc: 0.9842\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 21s - loss: 0.0409 - acc: 0.9879 - val_loss: 0.0488 - val_acc: 0.9847\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0400 - acc: 0.9883 - val_loss: 0.0465 - val_acc: 0.9850\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0390 - acc: 0.9883 - val_loss: 0.0467 - val_acc: 0.9852\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0389 - acc: 0.9882 - val_loss: 0.0485 - val_acc: 0.9847\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0393 - acc: 0.9881 - val_loss: 0.0474 - val_acc: 0.9855\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0365 - acc: 0.9890 - val_loss: 0.0460 - val_acc: 0.9860\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0366 - acc: 0.9892 - val_loss: 0.0433 - val_acc: 0.9865\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 18s - loss: 0.0362 - acc: 0.9890 - val_loss: 0.0433 - val_acc: 0.9857\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0349 - acc: 0.9897 - val_loss: 0.0447 - val_acc: 0.9860\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0354 - acc: 0.9895 - val_loss: 0.0430 - val_acc: 0.9865\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0342 - acc: 0.9897 - val_loss: 0.0416 - val_acc: 0.9868\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 20s - loss: 0.0320 - acc: 0.9906 - val_loss: 0.0419 - val_acc: 0.9867\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0319 - acc: 0.9904 - val_loss: 0.0408 - val_acc: 0.9874\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0319 - acc: 0.9905 - val_loss: 0.0395 - val_acc: 0.9869\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0334 - acc: 0.9896 - val_loss: 0.0427 - val_acc: 0.9860\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0335 - acc: 0.9900 - val_loss: 0.0399 - val_acc: 0.9874\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0315 - acc: 0.9909 - val_loss: 0.0409 - val_acc: 0.9868\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0311 - acc: 0.9905 - val_loss: 0.0447 - val_acc: 0.9861\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0310 - acc: 0.9906 - val_loss: 0.0374 - val_acc: 0.9885\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0287 - acc: 0.9915 - val_loss: 0.0394 - val_acc: 0.9873\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0296 - acc: 0.9911 - val_loss: 0.0413 - val_acc: 0.9870\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0290 - acc: 0.9913 - val_loss: 0.0392 - val_acc: 0.9878\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0272 - acc: 0.9918 - val_loss: 0.0412 - val_acc: 0.9865\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0266 - acc: 0.9920 - val_loss: 0.0388 - val_acc: 0.9880\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0269 - acc: 0.9917 - val_loss: 0.0453 - val_acc: 0.9852\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0262 - acc: 0.9922 - val_loss: 0.0398 - val_acc: 0.9871\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0282 - acc: 0.9914 - val_loss: 0.0377 - val_acc: 0.9889\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0265 - acc: 0.9921 - val_loss: 0.0362 - val_acc: 0.9885\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0246 - acc: 0.9929 - val_loss: 0.0371 - val_acc: 0.9877\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0237 - acc: 0.9930 - val_loss: 0.0398 - val_acc: 0.9876\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0256 - acc: 0.9921 - val_loss: 0.0362 - val_acc: 0.9882\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0222 - acc: 0.9937 - val_loss: 0.0365 - val_acc: 0.9887\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0234 - acc: 0.9932 - val_loss: 0.0377 - val_acc: 0.9876\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0230 - acc: 0.9933 - val_loss: 0.0349 - val_acc: 0.9892\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0223 - acc: 0.9937 - val_loss: 0.0385 - val_acc: 0.9878\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0219 - acc: 0.9939 - val_loss: 0.0364 - val_acc: 0.9888\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0221 - acc: 0.9934 - val_loss: 0.0357 - val_acc: 0.9888\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0234 - acc: 0.9931 - val_loss: 0.0353 - val_acc: 0.9899\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0211 - acc: 0.9939 - val_loss: 0.0395 - val_acc: 0.9873\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0211 - acc: 0.9936 - val_loss: 0.0355 - val_acc: 0.9892\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0211 - acc: 0.9938 - val_loss: 0.0358 - val_acc: 0.9886\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0215 - acc: 0.9935 - val_loss: 0.0359 - val_acc: 0.9884\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0222 - acc: 0.9935 - val_loss: 0.0365 - val_acc: 0.9882\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0217 - acc: 0.9936 - val_loss: 0.0356 - val_acc: 0.9884\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0194 - acc: 0.9941 - val_loss: 0.0359 - val_acc: 0.9883\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0186 - acc: 0.9945 - val_loss: 0.0369 - val_acc: 0.9877\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0185 - acc: 0.9948 - val_loss: 0.0335 - val_acc: 0.9901\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0187 - acc: 0.9947 - val_loss: 0.0370 - val_acc: 0.9885\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0182 - acc: 0.9948 - val_loss: 0.0342 - val_acc: 0.9895\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 20s - loss: 0.0176 - acc: 0.9952 - val_loss: 0.0325 - val_acc: 0.9895\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.0169 - acc: 0.9955 - val_loss: 0.0365 - val_acc: 0.9879\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0173 - acc: 0.9951 - val_loss: 0.0365 - val_acc: 0.9891\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0174 - acc: 0.9948 - val_loss: 0.0330 - val_acc: 0.9894\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0173 - acc: 0.9954 - val_loss: 0.0342 - val_acc: 0.9881\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.0189 - acc: 0.9944 - val_loss: 0.0351 - val_acc: 0.9887\n"
     ]
    }
   ],
   "source": [
    "###### from keras.layers import Layer, Lambda, Input\n",
    "from tensorflow.python.framework.ops import Tensor\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, Input, MaxPool2D\n",
    "from tensorflow.python.framework.ops import Tensor\n",
    "def global_average_pooling(x: Layer):\n",
    "    return K.mean(x, axis = (2,3))\n",
    "\n",
    "def global_average_pooling_shape(input_shape):\n",
    "    # return the dimensions corresponding with batch size and number of filters\n",
    "    return (input_shape[0], input_shape[-1])\n",
    "\n",
    "def build_global_average_pooling_layer(function, output_shape):\n",
    "    return Lambda(pooling_function, output_shape)\n",
    "\n",
    "inputs: Tensor = Input(shape=(28,28,1))\n",
    "x: Tensor = Conv2D(filters=32, kernel_size=5, activation='relu')(inputs)\n",
    "x: Tensor = MaxPool2D()(x)\n",
    "x: Tensor = Conv2D(filters=64, kernel_size=5, activation='relu')(x)\n",
    "x: Tensor = Lambda(lambda x: K.mean(x, axis=(1,2)), output_shape=global_average_pooling_shape)(x)\n",
    "x: Tensor = Dense(128, activation=\"relu\")(x)\n",
    "predictions: Tensor = Dense(10, activation=\"softmax\")(x)\n",
    "model: Model = Model(inputs=inputs, outputs=predictions)\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "from keras.callbacks import History\n",
    "history: History = model.fit(X_train_expanded, encoded_y_train,  \n",
    "                             validation_data=(X_test_expanded, encoded_y_test), epochs=100, batch_size=5126)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Class Activation Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist model\n",
    "save_filepath: str = \"class_activation_max_pool.h5\"\n",
    "model.save(save_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_image = X_train[2]\n",
    "first_image = first_image.reshape(28,28,1)\n",
    "img = np.array(first_image).reshape(1, 28, 28, 1)\n",
    "img.shape\n",
    "# img = np.array([np.transpose(np.float32(first_image), (2, 0, 1))])\n",
    "# img.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights is shape (64, 10)\n",
      "Conv2D output shape: (1, 26, 26, 64)\n",
      "Predictions: (1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights: np.ndarray = model.layers[-1].get_weights()[0] # class weights is of shape 32 x 10 (number of filter outputs x classes)\n",
    "print(f\"Class weights is shape {class_weights.shape}\")\n",
    "final_conv_layer: Conv2D = get_output_layer(model, \"conv2d_3\")\n",
    "\n",
    "input_tensor: Tensor = model.layers[0].input\n",
    "final_conv_layer_output: Tensor = final_conv_layer.output\n",
    "model_class_weights: Tensor = model.layers[-1].output\n",
    "    \n",
    "# K.function is a function factory that accepts arbitrary input layers and outputs arbitrary output layers\n",
    "get_output = K.function([input_tensor], [final_conv_layer_output, model_class_weights])\n",
    "\n",
    "[conv_outputs, predictions] = get_output([img])\n",
    "print(\"Conv2D output shape:\", conv_outputs.shape) # should match the shape of the outputs from the Conv2D layer\n",
    "print(\"Predictions:\", predictions.shape)\n",
    "np.argmax(predictions)\n",
    "# [conv_outputs, predictions] = get_output([img])\n",
    "# conv_outputs = conv_outputs[0, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b5817b89e8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAANR0lEQVR4nO3dX4xc5X3G8efxsjbBCYrX1I5jHKAES6WVaqrFVHGgVKSIoFQGJUGxlNSVUJ2LWApSLqC0VahyURI1oVEbIW3AjVMloFQJwhckxVgoCCVyvBAX2zUthBowdr1OncgmmPWf/fViD9Vids6M55yZM97f9yONZva8c+Y8GvnxmZ13Zl9HhADMffOaDgCgPyg7kARlB5Kg7EASlB1I4rx+Hmy+F8T5WtjPQwKpvKnf6ERMeraxSmW3fZOkr0sakvRARNxbdv/ztVDX+IYqhwRQYntsaznW9ct420OSviHpo5KulLTO9pXdPh6A3qryO/tqSS9GxEsRcULSw5LW1hMLQN2qlH25pFdn/Ly/2PY2tjfYHrc9flKTFQ4HoIoqZZ/tTYB3fPY2IsYiYjQiRoe1oMLhAFRRpez7Ja2Y8fPFkg5UiwOgV6qUfYekK2xfZnu+pE9J2lJPLAB163rqLSJO2d4o6d80PfW2KSL21JYMQK0qzbNHxGOSHqspC4Ae4uOyQBKUHUiCsgNJUHYgCcoOJEHZgSQoO5AEZQeSoOxAEpQdSIKyA0lQdiAJyg4kQdmBJCg7kARlB5Kg7EASlB1IgrIDSVB2IAnKDiRB2YEkKDuQBGUHkqDsQBKUHUiCsgNJUHYgCcoOJFFpFVdgkP3mE9e0HPvyV+4v3fdLt/1Z6XiM7+4qU5Mqld32PknHJJ2WdCoiRusIBaB+dZzZ/zgiflnD4wDoIX5nB5KoWvaQ9LjtZ2xvmO0OtjfYHrc9flKTFQ8HoFtVX8aviYgDtpdI2mr7+Yh4auYdImJM0pgkXeiRqHg8AF2qdGaPiAPF9YSkRyStriMUgPp1XXbbC22/563bkm6UdO7NRwBJVHkZv1TSI7bfepzvRsSPaknVA8fXlr/oOL54qHR8ZNNP64yDPpgYbX0u+9K+P+1jksHQddkj4iVJv19jFgA9xNQbkARlB5Kg7EASlB1IgrIDSaT5iuuB68r/X7vg8l+XP8CmGsOgHvPKp0vjA8dbjt2w5PnSfbf5Q11FGmSc2YEkKDuQBGUHkqDsQBKUHUiCsgNJUHYgiTTz7H/7sX8tHf/y3hv7lAR1Gbr8ktLx5/+o9YcjVv3s06X7vn/Hrq4yDTLO7EASlB1IgrIDSVB2IAnKDiRB2YEkKDuQRJp59mGfajoCanbeA290ve/xX1xYY5JzA2d2IAnKDiRB2YEkKDuQBGUHkqDsQBKUHUhizsyzT314Ven4tec/3ack6JdLF/5v1/uueOJ0jUnODW3P7LY32Z6wvXvGthHbW22/UFwv6m1MAFV18jL+W5JuOmPbXZK2RcQVkrYVPwMYYG3LHhFPSTpyxua1kjYXtzdLuqXmXABq1u0bdEsj4qAkFddLWt3R9gbb47bHT2qyy8MBqKrn78ZHxFhEjEbE6LAW9PpwAFrotuyHbC+TpOJ6or5IAHqh27JvkbS+uL1e0qP1xAHQK23n2W0/JOl6SRfZ3i/pi5LulfQ927dLekXSJ3sZshMvf+xdpeNLhi7oUxLU5bxLP1A6/omRLV0/9rv++1el43NxFr5t2SNiXYuhG2rOAqCH+LgskARlB5Kg7EASlB1IgrIDScyZr7ie98FjlfZ/8/n31pQEdXn1HxaWjq9ZMFU6/uDRi1sP/vpoN5HOaZzZgSQoO5AEZQeSoOxAEpQdSIKyA0lQdiCJOTPPXtWS8fI5W8xu6KLFpeOHPr6y5djIbftL9/3xygfbHP380tH7v9H6TyMuOfSTNo8993BmB5Kg7EASlB1IgrIDSVB2IAnKDiRB2YEkmGcvHB8p/3+v/JvV1Uxde1XpeAy5dPzVj7ReaefE+0+W7jtvfvkfTX782n8sHR8uj6b/Od0629+8dGvpvkemyj/7cMG88uxLt7f+GwdRuufcxJkdSIKyA0lQdiAJyg4kQdmBJCg7kARlB5KYM/Psk28Ol45PtZlZ/ee77ysd37Jx1Vln6tSdix8oHZ+n8sns43Gi5diB0+Vz0f90+PrS8Y88cUfp+Ht/Pr90fNnjh1qO+eXy77Mf3lu+DPfSofLPEMSOXaXj2bQ9s9veZHvC9u4Z2+6x/ZrtncXl5t7GBFBVJy/jvyXpplm23xcRq4rLY/XGAlC3tmWPiKckHelDFgA9VOUNuo22nyte5i9qdSfbG2yP2x4/qckKhwNQRbdlv1/S5ZJWSToo6aut7hgRYxExGhGjw2r9pQgAvdVV2SPiUEScjogpSd+UtLreWADq1lXZbS+b8eOtkna3ui+AwdB2nt32Q5Kul3SR7f2SvijpeturNP214H2SPtvDjB354Kd/Xjr+u3+3sXR8xdWv1RnnrDw50fpvq0vS4R+WrDMuafGe1vPN83+0o83Ry+eqV2q8zf7lymb5X7vzQ6X7Xr3gp6XjD7++vItEebUte0Ssm2Vzu7/eD2DA8HFZIAnKDiRB2YEkKDuQBGUHkpgzX3Ft57K/LJ/GGWTL9ErTEXrigusOV9r/r5/8eOn4Sv2s0uPPNZzZgSQoO5AEZQeSoOxAEpQdSIKyA0lQdiCJNPPsmHsueTTjwsvd48wOJEHZgSQoO5AEZQeSoOxAEpQdSIKyA0lQdiAJyg4kQdmBJCg7kARlB5Kg7EASlB1IgrIDSfB9dgysIZefi361crh0/H0/rDPNua/tmd32CttP2t5re4/tzxfbR2xvtf1Ccb2o93EBdKuTl/GnJH0hIn5H0h9K+pztKyXdJWlbRFwhaVvxM4AB1bbsEXEwIp4tbh+TtFfScklrJW0u7rZZ0i29CgmgurN6g872pZKukrRd0tKIOChN/4cgaUmLfTbYHrc9flKT1dIC6FrHZbf9bknfl3RHRBztdL+IGIuI0YgYHdaCbjICqEFHZbc9rOmifyciflBsPmR7WTG+TNJEbyICqEMn78Zb0oOS9kbE12YMbZG0vri9XtKj9cdDZqdjqvSieSq/4G06mWdfI+kzknbZ3llsu1vSvZK+Z/t2Sa9I+mRvIgKoQ9uyR8TTktxi+IZ64wDoFV7sAElQdiAJyg4kQdmBJCg7kARfccU5642r32g6wjmFMzuQBGUHkqDsQBKUHUiCsgNJUHYgCcoOJME8OwZWuz8ljbPDswkkQdmBJCg7kARlB5Kg7EASlB1IgrIDSTDPjsZMPvFbpeOnV031KUkOnNmBJCg7kARlB5Kg7EASlB1IgrIDSVB2IAlHRPkd7BWSvi3pfZKmJI1FxNdt3yPpLyQdLu56d0Q8VvZYF3okrjELvwK9sj226WgcmXXV5U4+VHNK0hci4lnb75H0jO2txdh9EfH3dQUF0DudrM9+UNLB4vYx23slLe91MAD1Oqvf2W1fKukqSduLTRttP2d7k+1FLfbZYHvc9vhJTVYKC6B7HZfd9rslfV/SHRFxVNL9ki6XtErTZ/6vzrZfRIxFxGhEjA5rQQ2RAXSjo7LbHtZ00b8TET+QpIg4FBGnI2JK0jclre5dTABVtS27bUt6UNLeiPjajO3LZtztVkm7648HoC6dvBu/RtJnJO2yvbPYdrekdbZXSQpJ+yR9ticJAdSik3fjn5Y027xd6Zw6gMHCJ+iAJCg7kARlB5Kg7EASlB1IgrIDSVB2IAnKDiRB2YEkKDuQBGUHkqDsQBKUHUiCsgNJtP1T0rUezD4s6eUZmy6S9Mu+BTg7g5ptUHNJZOtWndkuiYhZ18Lua9nfcXB7PCJGGwtQYlCzDWouiWzd6lc2XsYDSVB2IImmyz7W8PHLDGq2Qc0lka1bfcnW6O/sAPqn6TM7gD6h7EASjZTd9k22/9P2i7bvaiJDK7b32d5le6ft8YazbLI9YXv3jG0jtrfafqG4nnWNvYay3WP7teK522n75oayrbD9pO29tvfY/nyxvdHnriRXX563vv/ObntI0n9J+hNJ+yXtkLQuIv6jr0FasL1P0mhENP4BDNvXSXpd0rcj4veKbV+RdCQi7i3+o1wUEXcOSLZ7JL3e9DLexWpFy2YuMy7pFkl/rgafu5Jct6kPz1sTZ/bVkl6MiJci4oSkhyWtbSDHwIuIpyQdOWPzWkmbi9ubNf2Ppe9aZBsIEXEwIp4tbh+T9NYy440+dyW5+qKJsi+X9OqMn/drsNZ7D0mP237G9oamw8xiaUQclKb/8Uha0nCeM7VdxrufzlhmfGCeu26WP6+qibLPtpTUIM3/rYmIP5D0UUmfK16uojMdLePdL7MsMz4Qul3+vKomyr5f0ooZP18s6UADOWYVEQeK6wlJj2jwlqI+9NYKusX1RMN5/t8gLeM92zLjGoDnrsnlz5so+w5JV9i+zPZ8SZ+StKWBHO9ge2HxxolsL5R0owZvKeotktYXt9dLerTBLG8zKMt4t1pmXA0/d40vfx4Rfb9IulnT78j/QtJfNZGhRa7flvTvxWVP09kkPaTpl3UnNf2K6HZJiyVtk/RCcT0yQNn+RdIuSc9puljLGsr2YU3/avicpJ3F5eamn7uSXH153vi4LJAEn6ADkqDsQBKUHUiCsgNJUHYgCcoOJEHZgST+Dz3d83+Re2C/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(first_image.reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #Reshape to the network input shape (3, w, h).\n",
    "        img = np.array([np.transpose(np.float32(original_img), (2, 0, 1))])\n",
    "        \n",
    "        #Get the 512 input weights to the softmax.\n",
    "        class_weights = model.layers[-1].get_weights()[0]\n",
    "        final_conv_layer = get_output_layer(model, \"conv5_3\")\n",
    "        get_output = K.function([model.layers[0].input], \\\n",
    "                    [final_conv_layer.output, \n",
    "        model.layers[-1].output])\n",
    "        [conv_outputs, predictions] = get_output([img])\n",
    "        conv_outputs = conv_outputs[0, :, :, :]\n",
    "\n",
    "        #Create the class activation map.\n",
    "        cam = np.zeros(dtype = np.float32, shape = conv_outputs.shape[1:3])\n",
    "        target_class = 1\n",
    "        for i, w in enumerate(class_weights[:, target_class]):\n",
    "                cam += w * conv_outputs[i, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \n",
    "original_img = cv2.imread(image_path, 1)\n",
    "width, height, _ = original_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_vanilla_cnn(filters_layer1:int, filters_layer2:int, kernel_size:int, input_dims: GrayScaleImageShape)-> Model:\n",
    "    inputs: Tensor = Input(shape=input_dims)\n",
    "    x: Tensor = Conv2D(filters=filters_layer1, kernel_size=kernel_size, activation='relu')(inputs)\n",
    "    x: Tensor = Conv2D(filters=filters_layer2, kernel_size=kernel_size, activation='relu')(x)\n",
    "    x: Tensor = build_global_average_pooling_layer(global_average_pooling, )\n",
    "    predictions = Dense(K, activation=\"softmax\")(x)\n",
    "    print(predictions)\n",
    "\n",
    "    #compile model using accuracy to measure model performance\n",
    "    model: Model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=input_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-3de1ded8ceb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mattention_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'attention_vec'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ychen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ychen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    864\u001b[0m             \u001b[1;34m'kernel_constraint'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;34m'bias_constraint'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m         }\n\u001b[0m\u001b[0;32m    867\u001b[0m         \u001b[0mbase_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ychen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlegacy_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ychen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ychen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\initializers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, shape, dtype)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         return {\n\u001b[1;32m--> 209\u001b[1;33m             \u001b[1;34m'scale'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m             \u001b[1;34m'mode'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[1;34m'distribution'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'tuple'"
     ]
    }
   ],
   "source": [
    "from keras.layers import merge\n",
    "\n",
    "def build_model(input_dim):\n",
    "    inputs = Input(shape=input_dim)\n",
    "\n",
    "    # ATTENTION PART STARTS HERE\n",
    "    attention_probs = Dense(input_dim, activation='softmax', name='attention_vec')(inputs)\n",
    "    attention_mul = merge([inputs, attention_probs], output_shape=32, name='attention_mul', mode='mul')\n",
    "    # ATTENTION PART FINISHES HERE\n",
    "\n",
    "    attention_mul = Dense(64)(attention_mul)\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(input=[inputs], output=output)\n",
    "    return model\n",
    "\n",
    "inputs = Input(shape=input_dims)\n",
    "attention_probs = Dense(input_dims, activation='softmax', name='attention_vec')(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding shape from (60000, 28, 28) to (60000, 28, 28, 1)\n",
      "Expanding shape from (10000, 28, 28) to (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train.reshape((60000,1,28,28))\n",
    "\n",
    "def expand_tensor_shape(X_train: np.ndarray)-> np.ndarray:\n",
    "    new_shape: Tuple = X_train.shape + (1,)\n",
    "    print(f\"Expanding shape from {X_train.shape} to {new_shape}\")\n",
    "    return X_train.reshape(new_shape)\n",
    "\n",
    "X_train_expanded: np.ndarray = expand_tensor_shape(X_train)\n",
    "X_test_expanded: np.ndarray = expand_tensor_shape(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEI Face Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.JpegImagePlugin.JpegImageFile"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL.JpegImagePlugin import JpegImageFile\n",
    "\n",
    "image: JpegImageFile = load_img('1-01.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
