{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "ImageShape = Tuple[int, int]\n",
    "GrayScaleImageShape = Tuple[int, int, int]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Sandbox Baseline Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is (60000, 28, 28)\n",
      "The shape of y_train is (60000,)\n",
      "The shape of X_test is (10000, 28, 28)\n",
      "The shape of y_test is (10000,) - some example targets: [7 2 1 0 4]\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "Dataset = Tuple[np.ndarray, np.ndarray]\n",
    "\n",
    "#download mnist data and split into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(f\"The shape of X_train is {X_train.shape}\")\n",
    "print(f\"The shape of y_train is {y_train.shape}\")\n",
    "print(f\"The shape of X_test is {X_test.shape}\")\n",
    "print(f\"The shape of y_test is {y_test.shape} - some example targets: {y_test[:5]}\")\n",
    "mnist_image_shape: ImageShape = X_train.shape[1:]\n",
    "print(mnist_image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoding y_train (60000,) -> (60000, 10)\n",
      "One-hot encoding y_test (10000,) -> (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "OneHotEncodedTarget = np.ndarray\n",
    "Categories = int\n",
    "encoded_y_train: OneHotEncodedTarget = to_categorical(y_train)\n",
    "encoded_y_test: OneHotEncodedTarget = to_categorical(y_test)\n",
    "print(f\"One-hot encoding y_train {y_train.shape} -> {encoded_y_train.shape}\")\n",
    "print(f\"One-hot encoding y_test {y_test.shape} -> {encoded_y_test.shape}\")\n",
    "\n",
    "K: Categories = encoded_y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla CNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_3/Softmax:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, Input\n",
    "from tensorflow.python.framework.ops import Tensor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# define model architecture and hyperparameters\n",
    "NUM_FILTERS_L1 = 64\n",
    "NUM_FILTERS_L2 = 32\n",
    "KERNEL_SIZE = 3\n",
    "\n",
    "# the images are 28 x 28 (pixel size) x 1 (grayscale - if RGB, then 3)\n",
    "input_dims: GrayScaleImageShape = (28,28,1)\n",
    "\n",
    "def build_vanilla_cnn(filters_layer1:int, filters_layer2:int, kernel_size:int, input_dims: GrayScaleImageShape)-> Model:\n",
    "    inputs: Tensor = Input(shape=input_dims)\n",
    "    x: Tensor = Conv2D(filters=filters_layer1, kernel_size=kernel_size, activation='relu')(inputs)\n",
    "    x: Tensor = Conv2D(filters=filters_layer2, kernel_size=kernel_size, activation='relu')(x)\n",
    "    x: Tensor = Flatten()(x)\n",
    "    predictions = Dense(K, activation=\"softmax\")(x)\n",
    "    print(predictions)\n",
    "\n",
    "    #compile model using accuracy to measure model performance\n",
    "    model: Model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model: Model = build_vanilla_cnn(NUM_FILTERS_L1, NUM_FILTERS_L2, KERNEL_SIZE, input_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding shape from (60000, 28, 28) to (60000, 28, 28, 1)\n",
      "Expanding shape from (10000, 28, 28) to (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train.reshape((60000,1,28,28))\n",
    "\n",
    "def expand_tensor_shape(X_train: np.ndarray)-> np.ndarray:\n",
    "    new_shape: Tuple = X_train.shape + (1,)\n",
    "        \n",
    "#     new_tensor = X_train.reshape(new_shape).reshape((-1,1,28,28))\n",
    "    new_tensor = X_train.reshape(new_shape)\n",
    "    print(f\"Expanding shape from {X_train.shape} to {new_tensor.shape}\")\n",
    "    return new_tensor\n",
    "\n",
    "X_train_expanded: np.ndarray = expand_tensor_shape(X_train)\n",
    "X_test_expanded: np.ndarray = expand_tensor_shape(X_test)\n",
    "    \n",
    "    \n",
    "# train model and retrieve history\n",
    "# from keras.callbacks import History\n",
    "# history: History = model.fit(X_train_expanded, encoded_y_train, \n",
    "#                              validation_data=(X_test_expanded, encoded_y_test), epochs=2, batch_size=2058)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Average Pooling Layer\n",
    "\n",
    "Output shape of convolutional layer is typically `batch size x number of filters x width x height`. The GAP layer will take the average of the width/height axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(X_train_expanded, (-1,1,28,28)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_43 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "lambda_23 (Lambda)           (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 650.0\n",
      "Trainable params: 650.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 5s - loss: 6.7734 - acc: 0.1235 - val_loss: 3.8506 - val_acc: 0.1720\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 5s - loss: 2.6785 - acc: 0.1360 - val_loss: 2.2077 - val_acc: 0.1581\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 6s - loss: 2.1587 - acc: 0.1545 - val_loss: 2.1040 - val_acc: 0.1859\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 6s - loss: 2.0732 - acc: 0.1989 - val_loss: 2.0322 - val_acc: 0.2303\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 6s - loss: 2.0096 - acc: 0.2566 - val_loss: 1.9725 - val_acc: 0.2854\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.9535 - acc: 0.2890 - val_loss: 1.9176 - val_acc: 0.3039\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.9028 - acc: 0.3083 - val_loss: 1.8673 - val_acc: 0.3154\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.8559 - acc: 0.3199 - val_loss: 1.8217 - val_acc: 0.3251\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.8126 - acc: 0.3324 - val_loss: 1.7794 - val_acc: 0.3511\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.7736 - acc: 0.3468 - val_loss: 1.7389 - val_acc: 0.3673\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.7385 - acc: 0.3642 - val_loss: 1.7041 - val_acc: 0.3795\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.7056 - acc: 0.3762 - val_loss: 1.6659 - val_acc: 0.3784\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.6731 - acc: 0.3876 - val_loss: 1.6356 - val_acc: 0.4112\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.6471 - acc: 0.4012 - val_loss: 1.6102 - val_acc: 0.4111\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.6263 - acc: 0.4108 - val_loss: 1.5885 - val_acc: 0.4171\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.6070 - acc: 0.4253 - val_loss: 1.5709 - val_acc: 0.4189\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.5893 - acc: 0.4318 - val_loss: 1.5519 - val_acc: 0.4472\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.5720 - acc: 0.4407 - val_loss: 1.5341 - val_acc: 0.4489\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.5575 - acc: 0.4485 - val_loss: 1.5212 - val_acc: 0.4575\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.5401 - acc: 0.4619 - val_loss: 1.5029 - val_acc: 0.4591\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.5257 - acc: 0.4656 - val_loss: 1.4897 - val_acc: 0.4575\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.5101 - acc: 0.4750 - val_loss: 1.4667 - val_acc: 0.4996\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.4948 - acc: 0.4801 - val_loss: 1.4520 - val_acc: 0.4937\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.4770 - acc: 0.4932 - val_loss: 1.4356 - val_acc: 0.5093\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.4628 - acc: 0.5007 - val_loss: 1.4227 - val_acc: 0.5193\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.4489 - acc: 0.5070 - val_loss: 1.4099 - val_acc: 0.5190\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.4362 - acc: 0.5090 - val_loss: 1.3965 - val_acc: 0.5136\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.4215 - acc: 0.5185 - val_loss: 1.3788 - val_acc: 0.5239\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.4080 - acc: 0.5232 - val_loss: 1.3643 - val_acc: 0.5343\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.3946 - acc: 0.5303 - val_loss: 1.3566 - val_acc: 0.5501\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.3840 - acc: 0.5342 - val_loss: 1.3398 - val_acc: 0.5456\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.3696 - acc: 0.5438 - val_loss: 1.3254 - val_acc: 0.5659\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.3581 - acc: 0.5495 - val_loss: 1.3185 - val_acc: 0.5394\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.3465 - acc: 0.5516 - val_loss: 1.3087 - val_acc: 0.5629\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.3356 - acc: 0.5574 - val_loss: 1.2935 - val_acc: 0.5698\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.3249 - acc: 0.5600 - val_loss: 1.2820 - val_acc: 0.5647\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.3127 - acc: 0.5650 - val_loss: 1.2797 - val_acc: 0.5766\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.3012 - acc: 0.5713 - val_loss: 1.2661 - val_acc: 0.5573\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.2931 - acc: 0.5715 - val_loss: 1.2541 - val_acc: 0.5940\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.2846 - acc: 0.5746 - val_loss: 1.2469 - val_acc: 0.5713\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.2706 - acc: 0.5858 - val_loss: 1.2259 - val_acc: 0.6016\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.2586 - acc: 0.5924 - val_loss: 1.2166 - val_acc: 0.5963\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.2507 - acc: 0.5933 - val_loss: 1.2061 - val_acc: 0.6054\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.2407 - acc: 0.5986 - val_loss: 1.1958 - val_acc: 0.6114\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.2312 - acc: 0.6026 - val_loss: 1.1899 - val_acc: 0.6079\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.2222 - acc: 0.6065 - val_loss: 1.1831 - val_acc: 0.6059\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.2143 - acc: 0.6087 - val_loss: 1.1782 - val_acc: 0.6207\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.2048 - acc: 0.6139 - val_loss: 1.1593 - val_acc: 0.6261\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.1963 - acc: 0.6176 - val_loss: 1.1533 - val_acc: 0.6335\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.1868 - acc: 0.6221 - val_loss: 1.1469 - val_acc: 0.6319\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.1797 - acc: 0.6238 - val_loss: 1.1366 - val_acc: 0.6361\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.1694 - acc: 0.6283 - val_loss: 1.1321 - val_acc: 0.6366\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.1637 - acc: 0.6300 - val_loss: 1.1236 - val_acc: 0.6389\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.1552 - acc: 0.6339 - val_loss: 1.1169 - val_acc: 0.6313\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.1471 - acc: 0.6368 - val_loss: 1.1038 - val_acc: 0.6494\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.1401 - acc: 0.6394 - val_loss: 1.1099 - val_acc: 0.6415\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s - loss: 1.1322 - acc: 0.6417 - val_loss: 1.0959 - val_acc: 0.6528\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.1246 - acc: 0.6454 - val_loss: 1.0811 - val_acc: 0.6537\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.1186 - acc: 0.6474 - val_loss: 1.0783 - val_acc: 0.6564\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.1117 - acc: 0.6505 - val_loss: 1.0749 - val_acc: 0.6482\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.1038 - acc: 0.6528 - val_loss: 1.0664 - val_acc: 0.6602\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.0961 - acc: 0.6555 - val_loss: 1.0532 - val_acc: 0.6670\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.0893 - acc: 0.6595 - val_loss: 1.0512 - val_acc: 0.6585\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.0831 - acc: 0.6603 - val_loss: 1.0456 - val_acc: 0.6596\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.0766 - acc: 0.6638 - val_loss: 1.0442 - val_acc: 0.6537\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.0708 - acc: 0.6644 - val_loss: 1.0301 - val_acc: 0.6699\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.0645 - acc: 0.6660 - val_loss: 1.0208 - val_acc: 0.6813\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.0554 - acc: 0.6717 - val_loss: 1.0188 - val_acc: 0.6804\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.0509 - acc: 0.6720 - val_loss: 1.0220 - val_acc: 0.6654\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.0460 - acc: 0.6729 - val_loss: 1.0047 - val_acc: 0.6848\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.0401 - acc: 0.6755 - val_loss: 1.0048 - val_acc: 0.6839\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.0338 - acc: 0.6769 - val_loss: 1.0084 - val_acc: 0.6711\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.0341 - acc: 0.6739 - val_loss: 0.9993 - val_acc: 0.6751\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.0220 - acc: 0.6827 - val_loss: 0.9807 - val_acc: 0.6913\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.0170 - acc: 0.6829 - val_loss: 0.9831 - val_acc: 0.6823\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.0125 - acc: 0.6822 - val_loss: 0.9760 - val_acc: 0.6924\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.0078 - acc: 0.6855 - val_loss: 0.9768 - val_acc: 0.6852\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 6s - loss: 1.0021 - acc: 0.6864 - val_loss: 0.9659 - val_acc: 0.6914\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9968 - acc: 0.6887 - val_loss: 0.9573 - val_acc: 0.6972\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9900 - acc: 0.6925 - val_loss: 0.9518 - val_acc: 0.6985\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9854 - acc: 0.6918 - val_loss: 0.9492 - val_acc: 0.6985\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9806 - acc: 0.6933 - val_loss: 0.9425 - val_acc: 0.7029\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9758 - acc: 0.6953 - val_loss: 0.9393 - val_acc: 0.7010\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 7s - loss: 0.9694 - acc: 0.6977 - val_loss: 0.9380 - val_acc: 0.7059\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9663 - acc: 0.6975 - val_loss: 0.9297 - val_acc: 0.6988\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9610 - acc: 0.6996 - val_loss: 0.9295 - val_acc: 0.6994\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 7s - loss: 0.9571 - acc: 0.7010 - val_loss: 0.9253 - val_acc: 0.7055\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9538 - acc: 0.7003 - val_loss: 0.9191 - val_acc: 0.7060\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9481 - acc: 0.7032 - val_loss: 0.9103 - val_acc: 0.7077\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9430 - acc: 0.7050 - val_loss: 0.9061 - val_acc: 0.7082\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9379 - acc: 0.7068 - val_loss: 0.9008 - val_acc: 0.7103\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9339 - acc: 0.7082 - val_loss: 0.8997 - val_acc: 0.7082\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9305 - acc: 0.7084 - val_loss: 0.8967 - val_acc: 0.7131\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9264 - acc: 0.7096 - val_loss: 0.8888 - val_acc: 0.7178\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9214 - acc: 0.7111 - val_loss: 0.8903 - val_acc: 0.7097\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9215 - acc: 0.7095 - val_loss: 0.8854 - val_acc: 0.7128\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9139 - acc: 0.7131 - val_loss: 0.8768 - val_acc: 0.7191\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9089 - acc: 0.7150 - val_loss: 0.8785 - val_acc: 0.7199\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9050 - acc: 0.7158 - val_loss: 0.8680 - val_acc: 0.7224\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 6s - loss: 0.9020 - acc: 0.7166 - val_loss: 0.8695 - val_acc: 0.7226\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Layer, Lambda\n",
    "def global_average_pooling(x: Layer):\n",
    "    return K.mean(x, axis = (2,3))\n",
    "\n",
    "def global_average_pooling_shape(input_shape):\n",
    "    # return the dimensions corresponding with batch size and number of filters\n",
    "    return (input_shape[0], input_shape[-1])\n",
    "\n",
    "def build_global_average_pooling_layer(function, output_shape):\n",
    "    return Lambda(pooling_function, output_shape)\n",
    "\n",
    "inputs: Tensor = Input(shape=(28,28,1))\n",
    "x: Tensor = Conv2D(filters=32, kernel_size=3, activation='relu')(inputs)\n",
    "# x = Flatten()(x)\n",
    "x: Tensor = Lambda(lambda x: K.mean(x, axis=(1,2)), output_shape=global_average_pooling_shape)(x)\n",
    "predictions = Dense(10, activation=\"softmax\")(x)\n",
    "model: Model = Model(inputs=inputs, outputs=predictions)\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "from keras.callbacks import History\n",
    "history: History = model.fit(X_train_expanded, encoded_y_train,  validation_data=(X_test_expanded, encoded_y_test), epochs=100, batch_size=2058)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.Conv2D at 0x1fd3323ac50>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_image = X_train[0]\n",
    "first_image = first_image.reshape(28,28,1)\n",
    "\n",
    "img = np.array([np.transpose(np.float32(first_image), (2, 0, 1))])\n",
    "img.shape\n",
    "\n",
    "class_weights = model.layers[-1].get_weights()[0] # 32 x 10\n",
    "final_conv_layer = get_output_layer(model, \"conv2d_43\")\n",
    "final_conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_layer(model, layer_name):\n",
    "    # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "    layer = layer_dict[layer_name]\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \n",
    "original_img = cv2.imread(image_path, 1)\n",
    "width, height, _ = original_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer, Lambda\n",
    "def global_average_pooling(x: Layer):\n",
    "    return K.mean(x, axis = (2,3))\n",
    "\n",
    "def global_average_pooling_shape(input_shape):\n",
    "    # return only the first two dimensions (batch size and number of filters)\n",
    "    return input_shape[0:2]\n",
    "\n",
    "def build_global_average_pooling_layer(function, output_shape):\n",
    "    return Lambda(pooling_function, output_shape)\n",
    "\n",
    "\n",
    "def build_vanilla_cnn(filters_layer1:int, filters_layer2:int, kernel_size:int, input_dims: GrayScaleImageShape)-> Model:\n",
    "    inputs: Tensor = Input(shape=input_dims)\n",
    "    x: Tensor = Conv2D(filters=filters_layer1, kernel_size=kernel_size, activation='relu')(inputs)\n",
    "    x: Tensor = Conv2D(filters=filters_layer2, kernel_size=kernel_size, activation='relu')(x)\n",
    "    x: Tensor = build_global_average_pooling_layer(global_average_pooling, )\n",
    "    predictions = Dense(K, activation=\"softmax\")(x)\n",
    "    print(predictions)\n",
    "\n",
    "    #compile model using accuracy to measure model performance\n",
    "    model: Model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=input_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-3de1ded8ceb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mattention_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'attention_vec'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ychen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ychen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    864\u001b[0m             \u001b[1;34m'kernel_constraint'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;34m'bias_constraint'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m         }\n\u001b[0m\u001b[0;32m    867\u001b[0m         \u001b[0mbase_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ychen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlegacy_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ychen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ychen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\initializers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, shape, dtype)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         return {\n\u001b[1;32m--> 209\u001b[1;33m             \u001b[1;34m'scale'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m             \u001b[1;34m'mode'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[1;34m'distribution'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'tuple'"
     ]
    }
   ],
   "source": [
    "from keras.layers import merge\n",
    "\n",
    "def build_model(input_dim):\n",
    "    inputs = Input(shape=input_dim)\n",
    "\n",
    "    # ATTENTION PART STARTS HERE\n",
    "    attention_probs = Dense(input_dim, activation='softmax', name='attention_vec')(inputs)\n",
    "    attention_mul = merge([inputs, attention_probs], output_shape=32, name='attention_mul', mode='mul')\n",
    "    # ATTENTION PART FINISHES HERE\n",
    "\n",
    "    attention_mul = Dense(64)(attention_mul)\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(input=[inputs], output=output)\n",
    "    return model\n",
    "\n",
    "inputs = Input(shape=input_dims)\n",
    "attention_probs = Dense(input_dims, activation='softmax', name='attention_vec')(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding shape from (60000, 28, 28) to (60000, 28, 28, 1)\n",
      "Expanding shape from (10000, 28, 28) to (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train.reshape((60000,1,28,28))\n",
    "\n",
    "def expand_tensor_shape(X_train: np.ndarray)-> np.ndarray:\n",
    "    new_shape: Tuple = X_train.shape + (1,)\n",
    "    print(f\"Expanding shape from {X_train.shape} to {new_shape}\")\n",
    "    return X_train.reshape(new_shape)\n",
    "\n",
    "X_train_expanded: np.ndarray = expand_tensor_shape(X_train)\n",
    "X_test_expanded: np.ndarray = expand_tensor_shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "32928/60000 [===============>..............] - ETA: 1:37 - loss: 5.4845 - acc: 0.4824"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-1b91df2ca5d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m history: History = model.fit(X_train_expanded, encoded_y_train, \n\u001b[1;32m----> 4\u001b[1;33m                              validation_data=(X_test_expanded, encoded_y_test), epochs=2, batch_size=2058)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ychen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\ychen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ychen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ychen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ychen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.11421830420212928,\n",
       "  0.1322451029705997,\n",
       "  0.15506393317956932,\n",
       "  0.19153590463257378,\n",
       "  0.20397465853056024],\n",
       " 'val_acc': [0.9787, 0.9788, 0.9785, 0.9771, 0.9742],\n",
       " 'loss': [0.027731930499821027,\n",
       "  0.018710533776183872,\n",
       "  0.018969004292929897,\n",
       "  0.018248560158168024,\n",
       "  0.023170674585329343],\n",
       " 'acc': [0.9920166666666667,\n",
       "  0.9945,\n",
       "  0.9945333333333334,\n",
       "  0.9953666666666666,\n",
       "  0.9950166666666667]}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEI Face Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.JpegImagePlugin.JpegImageFile"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL.JpegImagePlugin import JpegImageFile\n",
    "\n",
    "image: JpegImageFile = load_img('1-01.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
