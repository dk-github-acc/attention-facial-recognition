{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "from keras import models, layers\n",
    "from keras import backend as K\n",
    "from skimage.transform import resize\n",
    "from keras.optimizers import Adam\n",
    "import json\n",
    "from tensorflow.python.framework.ops import Tensor\n",
    "from keras.utils import to_categorical\n",
    "import cv2\n",
    "from keras.layers import Dense, Conv2D, Flatten, Input, MaxPooling2D, Layer, Lambda\n",
    "\n",
    "import warnings\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "import random\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, Input\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import logging\n",
    "from typing import Tuple\n",
    "from keras.preprocessing.image import load_img\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Size of Image\n",
    "\n",
    "We define the size of the image, along with a scaling factor (in this case, default is `4`). The scaling factor plays a significant role in reducing the amount of computation, and weight updates, that the subsequent models must perform. They represent a tradeoff between model performance (richness of the feature set) and practical efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = int(480/4)\n",
    "HEIGHT = int(640/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Get Mappings Helper Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define two functions, `get_mappings` and `expand_tensor_shape`, that serve as helper functions for almost all test workflows. \n",
    "\n",
    "The `get_mappings` function is used to retrieve the mapping (a dictionary with keys as image filenames and values being their true class (ie. `male` or `smiling`). \n",
    "\n",
    "The `expand_tensor_shape` function is used to add an additional dimension at the end of the tensor. So for instance, a `40 x 50 x 3` tensor would be outputted as `40 x 50 x 3 x 1` after being passed into the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mappings(bucket_name: str, mapping_path: str) -> Dict[str, str]:\n",
    "    s3 = boto3.resource('s3')\n",
    "    faces_bucket = s3.Bucket(bucket_name)  # instantiate the bucket object\n",
    "\n",
    "    obj = s3.Object(bucket_name, mapping_path)  # fetch the mapping dictionary\n",
    "\n",
    "    json_string: str = obj.get()['Body'].read().decode('utf-8')\n",
    "    mappings_dict: Dict[str, str] = json.loads(\n",
    "        json_string)  # this mappings_dict contains filename -> gender class mapping\n",
    "    print(list(mappings_dict.items())[:3])  # print the first three entries of the mappings dictionary\n",
    "    return mappings_dict\n",
    "\n",
    "\n",
    "def expand_tensor_shape(X_train: np.ndarray) -> np.ndarray:\n",
    "    new_shape: Tuple = X_train.shape + (1,)\n",
    "    new_tensor = X_train.reshape(new_shape)\n",
    "    print(f\"Expanding shape from {X_train.shape} to {new_tensor.shape}\")\n",
    "    return new_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is /home/ubuntu/attention-facial-recognition\n",
      "[('1-01.jpg', 'male'), ('1-02.jpg', 'male'), ('1-03.jpg', 'male')]\n",
      "Downloading 1-11.jpg, saving as /home/ubuntu/attention-facial-recognition/faces/1-11.jpg\n",
      "An error occurred (404) when calling the HeadObject operation: Not Found:Error downloading 1-11.jpg\n",
      "Downloading 1-12.jpg, saving as /home/ubuntu/attention-facial-recognition/faces/1-12.jpg\n",
      "An error occurred (404) when calling the HeadObject operation: Not Found:Error downloading 1-12.jpg\n",
      "Downloading 1-13.jpg, saving as /home/ubuntu/attention-facial-recognition/faces/1-13.jpg\n",
      "An error occurred (404) when calling the HeadObject operation: Not Found:Error downloading 1-13.jpg\n",
      "Downloading 10-02.jpg, saving as /home/ubuntu/attention-facial-recognition/faces/10-02.jpg\n",
      "An error occurred (404) when calling the HeadObject operation: Not Found:Error downloading 10-02.jpg\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "warnings.filterwarnings('ignore')\n",
    "S3_BUCKET_NAME = \"fei-faces-sao-paulo\"\n",
    "mapping = 'classification/gender.json'\n",
    "\n",
    "print(f\"Current working directory is {cwd}\")\n",
    "s3 = boto3.client('s3')\n",
    "warnings.filterwarnings('ignore')\n",
    "IMAGE_LIMIT = 3000\n",
    "LOCAL_IMAGES_FOLDER = \"faces\"\n",
    "\n",
    "mappings_dict: Dict[str, str] = get_mappings(S3_BUCKET_NAME, mapping)\n",
    "\n",
    "target: List[str] = []  # this list will contain our actual tensors (as N-dimensional numpy arrays)\n",
    "images: List[np.ndarray] = []  # this list will contain our classes (male or female)\n",
    "\n",
    "for filename, gender in mappings_dict.items():\n",
    "\n",
    "    if \"-14\" in filename or \"-10\" in filename:  # these images are blurry or obscured\n",
    "        continue\n",
    "\n",
    "    local_filename: str = os.path.join(cwd, LOCAL_IMAGES_FOLDER, filename)\n",
    "    try:\n",
    "        if not os.path.isfile(local_filename):  # if file does not exist locally\n",
    "            print(f\"Downloading {filename}, saving as {local_filename}\")\n",
    "            s3.download_file(S3_BUCKET_NAME, filename, local_filename)\n",
    "        else:\n",
    "            logging.debug(f\"Found a local copy of {local_filename}\")\n",
    "\n",
    "        # use the Keras image API to load in an image\n",
    "        img = load_img(local_filename)\n",
    "        #print(\"Resizing\")\n",
    "        img = img.resize((HEIGHT, WIDTH))\n",
    "        #img = img.convert('L')  # convert o gray scale\n",
    "        # report details about the image\n",
    "        images.append(np.array(img))\n",
    "        target.append(gender)\n",
    "        if len(images) == IMAGE_LIMIT:\n",
    "            print(\"Breaking after reaching image limit.\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"{e}:Error downloading {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Target to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoding target vector (2396,) -> (2396, 2)\n",
      "There are 2 classes to predict.\n"
     ]
    }
   ],
   "source": [
    "binary_target = np.array(list(map(lambda gender: 0 if gender == 'male' else 1, target)))\n",
    "encoded_target = to_categorical(binary_target)\n",
    "\n",
    "print(f\"One-hot encoding target vector {binary_target.shape} -> {encoded_target.shape}\")\n",
    "NUM_CLASSSES = encoded_target.shape[1]\n",
    "print(f\"There are {NUM_CLASSSES} classes to predict.\")\n",
    "\n",
    "indices = np.linspace(0, len(binary_target) - 1, len(binary_target))\n",
    "validation_indices = np.random.choice(indices, size=int(len(binary_target) * 0.3), replace=False).astype(int)\n",
    "training_indices = set(indices).difference(set(validation_indices))\n",
    "training_indices = np.array(list(training_indices)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Custom Neural Network VGG Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "_KERAS_BACKEND = keras.backend\n",
    "_KERAS_LAYERS = keras.layers\n",
    "_KERAS_MODELS = keras.models\n",
    "_KERAS_UTILS = keras.utils\n",
    "\n",
    "\n",
    "WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'\n",
    "                'releases/download/v0.1/'\n",
    "                'vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n",
    "                       'releases/download/v0.1/'\n",
    "                       'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "def get_submodules_from_kwargs(kwargs):\n",
    "    backend = kwargs.get('backend', _KERAS_BACKEND)\n",
    "    layers = kwargs.get('layers', _KERAS_LAYERS)\n",
    "    models = kwargs.get('models', _KERAS_MODELS)\n",
    "    utils = kwargs.get('utils', _KERAS_UTILS)\n",
    "    for key in kwargs.keys():\n",
    "        if key not in ['backend', 'layers', 'models', 'utils']:\n",
    "            raise TypeError('Invalid keyword argument: %s', key)\n",
    "    return backend, layers, models, utils\n",
    "\n",
    "def _obtain_input_shape(input_shape,\n",
    "                        default_size,\n",
    "                        min_size,\n",
    "                        data_format,\n",
    "                        require_flatten,\n",
    "                        weights=None):\n",
    "    \"\"\"Internal utility to compute/validate a model's input shape.\n",
    "    # Arguments\n",
    "        input_shape: Either None (will return the default network input shape),\n",
    "            or a user-provided shape to be validated.\n",
    "        default_size: Default input width/height for the model.\n",
    "        min_size: Minimum input width/height accepted by the model.\n",
    "        data_format: Image data format to use.\n",
    "        require_flatten: Whether the model is expected to\n",
    "            be linked to a classifier via a Flatten layer.\n",
    "        weights: One of `None` (random initialization)\n",
    "            or 'imagenet' (pre-training on ImageNet).\n",
    "            If weights='imagenet' input channels must be equal to 3.\n",
    "    # Returns\n",
    "        An integer shape tuple (may include None entries).\n",
    "    # Raises\n",
    "        ValueError: In case of invalid argument values.\n",
    "    \"\"\"\n",
    "    if weights != 'imagenet' and input_shape and len(input_shape) == 3:\n",
    "        if data_format == 'channels_first':\n",
    "            if input_shape[0] not in {1, 3}:\n",
    "                warnings.warn(\n",
    "                    'This model usually expects 1 or 3 input channels. '\n",
    "                    'However, it was passed an input_shape with ' +\n",
    "                    str(input_shape[0]) + ' input channels.')\n",
    "            default_shape = (input_shape[0], default_size, default_size)\n",
    "        else:\n",
    "            if input_shape[-1] not in {1, 3}:\n",
    "                warnings.warn(\n",
    "                    'This model usually expects 1 or 3 input channels. '\n",
    "                    'However, it was passed an input_shape with ' +\n",
    "                    str(input_shape[-1]) + ' input channels.')\n",
    "            default_shape = (default_size, default_size, input_shape[-1])\n",
    "    else:\n",
    "        if data_format == 'channels_first':\n",
    "            default_shape = (3, default_size, default_size)\n",
    "        else:\n",
    "            default_shape = (default_size, default_size, 3)\n",
    "    if weights == 'imagenet' and require_flatten:\n",
    "        if input_shape is not None:\n",
    "            if input_shape != default_shape:\n",
    "                raise ValueError('When setting `include_top=True` '\n",
    "                                 'and loading `imagenet` weights, '\n",
    "                                 '`input_shape` should be ' +\n",
    "                                 str(default_shape) + '.')\n",
    "        return default_shape\n",
    "    if input_shape:\n",
    "        if data_format == 'channels_first':\n",
    "            if input_shape is not None:\n",
    "                if len(input_shape) != 3:\n",
    "                    raise ValueError(\n",
    "                        '`input_shape` must be a tuple of three integers.')\n",
    "                if input_shape[0] != 3 and weights == 'imagenet':\n",
    "                    raise ValueError('The input must have 3 channels; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "                if ((input_shape[1] is not None and input_shape[1] < min_size) or\n",
    "                   (input_shape[2] is not None and input_shape[2] < min_size)):\n",
    "                    raise ValueError('Input size must be at least ' +\n",
    "                                     str(min_size) + 'x' + str(min_size) +\n",
    "                                     '; got `input_shape=' +\n",
    "                                     str(input_shape) + '`')\n",
    "        else:\n",
    "            if input_shape is not None:\n",
    "                if len(input_shape) != 3:\n",
    "                    raise ValueError(\n",
    "                        '`input_shape` must be a tuple of three integers.')\n",
    "                if input_shape[-1] != 3 and weights == 'imagenet':\n",
    "                    raise ValueError('The input must have 3 channels; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "                if ((input_shape[0] is not None and input_shape[0] < min_size) or\n",
    "                   (input_shape[1] is not None and input_shape[1] < min_size)):\n",
    "                    raise ValueError('Input size must be at least ' +\n",
    "                                     str(min_size) + 'x' + str(min_size) +\n",
    "                                     '; got `input_shape=' +\n",
    "                                     str(input_shape) + '`')\n",
    "    else:\n",
    "        if require_flatten:\n",
    "            input_shape = default_shape\n",
    "        else:\n",
    "            if data_format == 'channels_first':\n",
    "                input_shape = (3, None, None)\n",
    "            else:\n",
    "                input_shape = (None, None, 3)\n",
    "    if require_flatten:\n",
    "        if None in input_shape:\n",
    "            raise ValueError('If `include_top` is True, '\n",
    "                             'you should specify a static `input_shape`. '\n",
    "                             'Got `input_shape=' + str(input_shape) + '`')\n",
    "    return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Augmented Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import concatenate\n",
    "\n",
    "from keras import initializers\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def _conv_layer(filters, kernel_size, strides=(1, 1), padding='same', name=None):\n",
    "    return Conv2D(filters, kernel_size, strides=strides, padding=padding,\n",
    "                  use_bias=True, kernel_initializer='he_normal', name=name)\n",
    "\n",
    "\n",
    "def _normalize_depth_vars(depth_k, depth_v, filters):\n",
    "    \"\"\"\n",
    "    Accepts depth_k and depth_v as either floats or integers\n",
    "    and normalizes them to integers.\n",
    "    Args:\n",
    "        depth_k: float or int.\n",
    "        depth_v: float or int.\n",
    "        filters: number of output filters.\n",
    "    Returns:\n",
    "        depth_k, depth_v as integers.\n",
    "    \"\"\"\n",
    "\n",
    "    if type(depth_k) == float:\n",
    "        depth_k = int(filters * depth_k)\n",
    "    else:\n",
    "        depth_k = int(depth_k)\n",
    "\n",
    "    if type(depth_v) == float:\n",
    "        depth_v = int(filters * depth_v)\n",
    "    else:\n",
    "        depth_v = int(depth_v)\n",
    "\n",
    "    return depth_k, depth_v\n",
    "\n",
    "\n",
    "class AttentionAugmentation2D(Layer):\n",
    "\n",
    "    def __init__(self, depth_k, depth_v, num_heads, relative=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Applies attention augmentation on a convolutional layer\n",
    "        output.\n",
    "        Args:\n",
    "            depth_k: float or int. Number of filters for k.\n",
    "            Computes the number of filters for `v`.\n",
    "            If passed as float, computed as `filters * depth_k`.\n",
    "        depth_v: float or int. Number of filters for v.\n",
    "            Computes the number of filters for `k`.\n",
    "            If passed as float, computed as `filters * depth_v`.\n",
    "        num_heads: int. Number of attention heads.\n",
    "            Must be set such that `depth_k // num_heads` is > 0.\n",
    "        relative: bool, whether to use relative encodings.\n",
    "        Raises:\n",
    "            ValueError: if depth_v or depth_k is not divisible by\n",
    "                num_heads.\n",
    "        Returns:\n",
    "            Output tensor of shape\n",
    "            -   [Batch, Height, Width, Depth_V] if\n",
    "                channels_last data format.\n",
    "            -   [Batch, Depth_V, Height, Width] if\n",
    "                channels_first data format.\n",
    "        \"\"\"\n",
    "        super(AttentionAugmentation2D, self).__init__(**kwargs)\n",
    "\n",
    "        if depth_k % num_heads != 0:\n",
    "            raise ValueError('`depth_k` (%d) is not divisible by `num_heads` (%d)' % (\n",
    "                depth_k, num_heads))\n",
    "\n",
    "        if depth_v % num_heads != 0:\n",
    "            raise ValueError('`depth_v` (%d) is not divisible by `num_heads` (%d)' % (\n",
    "                depth_v, num_heads))\n",
    "\n",
    "        if depth_k // num_heads < 1.:\n",
    "            raise ValueError('depth_k / num_heads cannot be less than 1 ! '\n",
    "                             'Given depth_k = %d, num_heads = %d' % (\n",
    "                             depth_k, num_heads))\n",
    "\n",
    "        if depth_v // num_heads < 1.:\n",
    "            raise ValueError('depth_v / num_heads cannot be less than 1 ! '\n",
    "                             'Given depth_v = %d, num_heads = %d' % (\n",
    "                                 depth_v, num_heads))\n",
    "\n",
    "        self.depth_k = depth_k\n",
    "        self.depth_v = depth_v\n",
    "        self.num_heads = num_heads\n",
    "        self.relative = relative\n",
    "\n",
    "        self.axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self._shape = input_shape\n",
    "\n",
    "        # normalize the format of depth_v and depth_k\n",
    "        self.depth_k, self.depth_v = _normalize_depth_vars(self.depth_k, self.depth_v,\n",
    "                                                           input_shape)\n",
    "\n",
    "        if self.axis == 1:\n",
    "            _, channels, height, width = input_shape\n",
    "        else:\n",
    "            _, height, width, channels = input_shape\n",
    "\n",
    "        if self.relative:\n",
    "            dk_per_head = self.depth_k // self.num_heads\n",
    "\n",
    "            if dk_per_head == 0:\n",
    "                print('dk per head', dk_per_head)\n",
    "\n",
    "            self.key_relative_w = self.add_weight('key_rel_w',\n",
    "                                                  shape=[2 * width - 1, dk_per_head],\n",
    "                                                  initializer=initializers.RandomNormal(\n",
    "                                                      stddev=dk_per_head ** -0.5))\n",
    "\n",
    "            self.key_relative_h = self.add_weight('key_rel_h',\n",
    "                                                  shape=[2 * height - 1, dk_per_head],\n",
    "                                                  initializer=initializers.RandomNormal(\n",
    "                                                      stddev=dk_per_head ** -0.5))\n",
    "\n",
    "        else:\n",
    "            self.key_relative_w = None\n",
    "            self.key_relative_h = None\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if self.axis == 1:\n",
    "            # If channels first, force it to be channels last for these ops\n",
    "            inputs = K.permute_dimensions(inputs, [0, 2, 3, 1])\n",
    "\n",
    "        q, k, v = tf.split(inputs, [self.depth_k, self.depth_k, self.depth_v], axis=-1)\n",
    "\n",
    "        q = self.split_heads_2d(q)\n",
    "        k = self.split_heads_2d(k)\n",
    "        v = self.split_heads_2d(v)\n",
    "\n",
    "        # scale query\n",
    "        depth_k_heads = self.depth_k / self.num_heads\n",
    "        q *= (depth_k_heads ** -0.5)\n",
    "\n",
    "        # [Batch, num_heads, height * width, depth_k or depth_v] if axis == -1\n",
    "        qk_shape = [self._batch, self.num_heads, self._height * self._width, self.depth_k // self.num_heads]\n",
    "        v_shape = [self._batch, self.num_heads, self._height * self._width, self.depth_v // self.num_heads]\n",
    "        flat_q = K.reshape(q, K.stack(qk_shape))\n",
    "        flat_k = K.reshape(k, K.stack(qk_shape))\n",
    "        flat_v = K.reshape(v, K.stack(v_shape))\n",
    "\n",
    "        # [Batch, num_heads, HW, HW]\n",
    "        logits = tf.matmul(flat_q, flat_k, transpose_b=True)\n",
    "\n",
    "        # Apply relative encodings\n",
    "        if self.relative:\n",
    "            h_rel_logits, w_rel_logits = self.relative_logits(q)\n",
    "            logits += h_rel_logits\n",
    "            logits += w_rel_logits\n",
    "\n",
    "        weights = K.softmax(logits, axis=-1)\n",
    "        attn_out = tf.matmul(weights, flat_v)\n",
    "\n",
    "        attn_out_shape = [self._batch, self.num_heads, self._height, self._width, self.depth_v // self.num_heads]\n",
    "        attn_out_shape = K.stack(attn_out_shape)\n",
    "        attn_out = K.reshape(attn_out, attn_out_shape)\n",
    "        attn_out = self.combine_heads_2d(attn_out)\n",
    "        # [batch, height, width, depth_v]\n",
    "\n",
    "        if self.axis == 1:\n",
    "            # return to [batch, depth_v, height, width] for channels first\n",
    "            attn_out = K.permute_dimensions(attn_out, [0, 3, 1, 2])\n",
    "\n",
    "        return attn_out\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[self.axis] = self.depth_v\n",
    "        return tuple(output_shape)\n",
    "\n",
    "    def split_heads_2d(self, ip):\n",
    "        tensor_shape = K.shape(ip)\n",
    "\n",
    "        # batch, height, width, channels for axis = -1\n",
    "        tensor_shape = [tensor_shape[i] for i in range(len(self._shape))]\n",
    "\n",
    "        batch = tensor_shape[0]\n",
    "        height = tensor_shape[1]\n",
    "        width = tensor_shape[2]\n",
    "        channels = tensor_shape[3]\n",
    "\n",
    "        # Save the spatial tensor dimensions\n",
    "        self._batch = batch\n",
    "        self._height = height\n",
    "        self._width = width\n",
    "\n",
    "        ret_shape = K.stack([batch, height, width,  self.num_heads, channels // self.num_heads])\n",
    "        split = K.reshape(ip, ret_shape)\n",
    "        transpose_axes = (0, 3, 1, 2, 4)\n",
    "        split = K.permute_dimensions(split, transpose_axes)\n",
    "\n",
    "        return split\n",
    "\n",
    "    def relative_logits(self, q):\n",
    "        shape = K.shape(q)\n",
    "        # [batch, num_heads, H, W, depth_v]\n",
    "        shape = [shape[i] for i in range(5)]\n",
    "\n",
    "        height = shape[2]\n",
    "        width = shape[3]\n",
    "\n",
    "        rel_logits_w = self.relative_logits_1d(q, self.key_relative_w, height, width,\n",
    "                                               transpose_mask=[0, 1, 2, 4, 3, 5])\n",
    "\n",
    "        rel_logits_h = self.relative_logits_1d(\n",
    "            K.permute_dimensions(q, [0, 1, 3, 2, 4]),\n",
    "            self.key_relative_h, width, height,\n",
    "            transpose_mask=[0, 1, 4, 2, 5, 3])\n",
    "\n",
    "        return rel_logits_h, rel_logits_w\n",
    "\n",
    "    def relative_logits_1d(self, q, rel_k, H, W, transpose_mask):\n",
    "        rel_logits = tf.einsum('bhxyd,md->bhxym', q, rel_k)\n",
    "        rel_logits = K.reshape(rel_logits, [-1, self.num_heads * H, W, 2 * W - 1])\n",
    "        rel_logits = self.rel_to_abs(rel_logits)\n",
    "        rel_logits = K.reshape(rel_logits, [-1, self.num_heads, H, W, W])\n",
    "        rel_logits = K.expand_dims(rel_logits, axis=3)\n",
    "        rel_logits = K.tile(rel_logits, [1, 1, 1, H, 1, 1])\n",
    "        rel_logits = K.permute_dimensions(rel_logits, transpose_mask)\n",
    "        rel_logits = K.reshape(rel_logits, [-1, self.num_heads, H * W, H * W])\n",
    "        return rel_logits\n",
    "\n",
    "    def rel_to_abs(self, x):\n",
    "        shape = K.shape(x)\n",
    "        shape = [shape[i] for i in range(3)]\n",
    "        B, Nh, L, = shape\n",
    "        col_pad = K.zeros(K.stack([B, Nh, L, 1]))\n",
    "        x = K.concatenate([x, col_pad], axis=3)\n",
    "        flat_x = K.reshape(x, [B, Nh, L * 2 * L])\n",
    "        flat_pad = K.zeros(K.stack([B, Nh, L - 1]))\n",
    "        flat_x_padded = K.concatenate([flat_x, flat_pad], axis=2)\n",
    "        final_x = K.reshape(flat_x_padded, [B, Nh, L + 1, 2 * L - 1])\n",
    "        final_x = final_x[:, :, :L, L - 1:]\n",
    "        return final_x\n",
    "\n",
    "    def combine_heads_2d(self, inputs):\n",
    "        # [batch, num_heads, height, width, depth_v // num_heads]\n",
    "        transposed = K.permute_dimensions(inputs, [0, 2, 3, 1, 4])\n",
    "        # [batch, height, width, num_heads, depth_v // num_heads]\n",
    "        shape = K.shape(transposed)\n",
    "        shape = [shape[i] for i in range(5)]\n",
    "\n",
    "        a, b = shape[-2:]\n",
    "        ret_shape = K.stack(shape[:-2] + [a * b])\n",
    "        # [batch, height, width, depth_v]\n",
    "        return K.reshape(transposed, ret_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'depth_k': self.depth_k,\n",
    "            'depth_v': self.depth_v,\n",
    "            'num_heads': self.num_heads,\n",
    "            'relative': self.relative,\n",
    "        }\n",
    "        base_config = super(AttentionAugmentation2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "def augmented_conv2d(ip, filters, kernel_size=(3, 3), strides=(1, 1),\n",
    "                     depth_k=0.2, depth_v=0.2, num_heads=8, relative_encodings=True):\n",
    "    \"\"\"\n",
    "    Builds an Attention Augmented Convolution block.\n",
    "    Args:\n",
    "        ip: keras tensor.\n",
    "        filters: number of output filters.\n",
    "        kernel_size: convolution kernel size.\n",
    "        strides: strides of the convolution.\n",
    "        depth_k: float or int. Number of filters for k.\n",
    "            Computes the number of filters for `v`.\n",
    "            If passed as float, computed as `filters * depth_k`.\n",
    "        depth_v: float or int. Number of filters for v.\n",
    "            Computes the number of filters for `k`.\n",
    "            If passed as float, computed as `filters * depth_v`.\n",
    "        num_heads: int. Number of attention heads.\n",
    "            Must be set such that `depth_k // num_heads` is > 0.\n",
    "        relative_encodings: bool. Whether to use relative\n",
    "            encodings or not.\n",
    "    Returns:\n",
    "        a keras tensor.\n",
    "    \"\"\"\n",
    "    print(f\"Using {num_heads} number of heads\")\n",
    "    # input_shape = K.int_shape(ip)\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    depth_k, depth_v = _normalize_depth_vars(depth_k, depth_v, filters)\n",
    "\n",
    "    conv_out = _conv_layer(filters - depth_v, kernel_size, strides)(ip)\n",
    "\n",
    "    # Augmented Attention Block\n",
    "    qkv_conv = _conv_layer(2 * depth_k + depth_v, (1, 1), strides)(ip)\n",
    "    attn_out = AttentionAugmentation2D(depth_k, depth_v, num_heads, relative_encodings)(qkv_conv)\n",
    "    attn_out = _conv_layer(depth_v, kernel_size=(1, 1))(attn_out)\n",
    "\n",
    "    output = concatenate([conv_out, attn_out], axis=channel_axis)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_custom_VGG16(include_top=False, # switched from True to False\n",
    "          weights='imagenet',\n",
    "          input_tensor=None,\n",
    "          input_shape=None,\n",
    "          pooling=None,\n",
    "          classes=2, # switched from 1000 default classes to 2 classes\n",
    "          **kwargs):\n",
    "    \"\"\"Instantiates the VGG16 architecture.\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization),\n",
    "              'imagenet' (pre-training on ImageNet),\n",
    "              or the path to the weights file to be loaded.\n",
    "        input_tensor: optional Keras tensor\n",
    "            (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)`\n",
    "            (with `channels_last` data format)\n",
    "            or `(3, 224, 224)` (with `channels_first` data format).\n",
    "            It should have exactly 3 input channels,\n",
    "            and width and height should be no smaller than 32.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional block.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional block, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "\n",
    "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization), `imagenet` '\n",
    "                         '(pre-training on ImageNet), '\n",
    "                         'or the path to the weights file to be loaded.')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=32,\n",
    "                                      data_format=backend.image_data_format(),\n",
    "                                      require_flatten=include_top,\n",
    "                                      weights=weights)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    # Multi-Headed Attention Layer\n",
    "    x = augmented_conv2d(img_input, filters=10, kernel_size=(3, 3), depth_k=0.2, depth_v=0.2,  # dk/v (0.2) * f_out (20) = 4\n",
    "                         num_heads=2, relative_encodings=True)         \n",
    "    # Block 1\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(x)\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv2')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = layers.Flatten(name='flatten')(x)\n",
    "        x = layers.Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = layers.Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = models.Model(inputs, x, name='vgg16')\n",
    "\n",
    "    # Load weights.\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = keras_utils.get_file(\n",
    "                'vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                WEIGHTS_PATH,\n",
    "                cache_subdir='models',\n",
    "                file_hash='64373286793e3c8b2b4e3219cbf3544b')\n",
    "        else:\n",
    "            weights_path = keras_utils.get_file(\n",
    "                'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                WEIGHTS_PATH_NO_TOP,\n",
    "                cache_subdir='models',\n",
    "                file_hash='6d6bbae143d832006294945121d1f1fc')\n",
    "        model.load_weights(weights_path)\n",
    "        if backend.backend() == 'theano':\n",
    "            keras_utils.convert_all_kernels_in_model(model)\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 number of heads\n",
      "(?, 60, 80, 12)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_34 (InputLayer)           (None, 60, 80, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 60, 80, 6)    24          input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_augmentation2d_23 (At (None, 60, 80, 2)    556         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 60, 80, 10)   280         input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 60, 80, 2)    6           attention_augmentation2d_23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 60, 80, 12)   0           conv2d_63[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 120, 160, 3)  0           concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Model)                   (None, 512)          14714688    reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 128)          65664       vgg16[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 2)            258         batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 14,781,988\n",
      "Trainable params: 7,146,468\n",
      "Non-trainable params: 7,635,520\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Reshape\n",
    "\n",
    "input_dims = (WIDTH, HEIGHT, 3)\n",
    "inputs = Input(shape=input_dims)\n",
    "x = augmented_conv2d(inputs, filters=12, kernel_size=(3, 3), depth_k=0.2, depth_v=0.2,  # dk/v (0.2) * f_out (20) = 4\n",
    "                         num_heads=1, relative_encodings=True)\n",
    "print(x.shape)\n",
    "vgg=VGG16(include_top=False, pooling='avg', weights='imagenet',input_shape=(WIDTH, HEIGHT, 3))\n",
    "for layer in vgg.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Reshape((WIDTH * 2, HEIGHT * 2, 3))(x)\n",
    "x = vgg(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer=Adam(lr=0.0000001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding shape from (1678, 60, 80, 3) to (1678, 60, 80, 3, 1)\n",
      "Expanding shape from (718, 60, 80, 3) to (718, 60, 80, 3, 1)\n",
      "Expanding shape from (2396, 60, 80, 3) to (2396, 60, 80, 3, 1)\n",
      "The shape of X_train_expanded is (1678, 60, 80, 3, 1)\n",
      "The shape of X_test_expanded is (718, 60, 80, 3, 1)\n",
      "The shape of X_train is (1678, 60, 80, 3)\n",
      "The shape of y_train is (1678, 2)\n",
      "The shape of X_test is (718, 60, 80, 3)\n",
      "The shape of y_test is (718, 2) - some example targets:\n",
      " [[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "images: np.ndarray = np.array(images)\n",
    "X_train = images[training_indices]\n",
    "y_train = binary_target[training_indices]\n",
    "y_train = encoded_target[training_indices]\n",
    "X_test = images[validation_indices]\n",
    "y_test = binary_target[validation_indices]\n",
    "y_test = encoded_target[validation_indices]\n",
    "X_train_expanded: np.ndarray = expand_tensor_shape(X_train)\n",
    "X_test_expanded: np.ndarray = expand_tensor_shape(X_test)\n",
    "images_expanded = expand_tensor_shape(images)\n",
    "\n",
    "print(f\"The shape of X_train_expanded is {X_train_expanded.shape}\")\n",
    "print(f\"The shape of X_test_expanded is {X_test_expanded.shape}\")\n",
    "print(f\"The shape of X_train is {X_train.shape}\")\n",
    "print(f\"The shape of y_train is {y_train.shape}\")\n",
    "print(f\"The shape of X_test is {X_test.shape}\")\n",
    "print(f\"The shape of y_test is {y_test.shape} - some example targets:\\n {y_test[:5]}\")\n",
    "\n",
    "input_dims = (WIDTH, HEIGHT, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_34 (InputLayer)           (None, 60, 80, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 60, 80, 6)    24          input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_augmentation2d_23 (At (None, 60, 80, 2)    556         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 60, 80, 10)   280         input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 60, 80, 2)    6           attention_augmentation2d_23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 60, 80, 12)   0           conv2d_63[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 120, 160, 3)  0           concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Model)                   (None, 512)          14714688    reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 128)          65664       vgg16[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 2)            258         batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 14,781,988\n",
      "Trainable params: 7,146,468\n",
      "Non-trainable params: 7,635,520\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1677 samples, validate on 719 samples\n",
      "Epoch 1/10\n",
      "1677/1677 [==============================] - 154s 92ms/step - loss: 0.7078 - acc: 0.5897 - val_loss: 0.5988 - val_acc: 0.7079\n",
      "Epoch 2/10\n",
      "1677/1677 [==============================] - 154s 92ms/step - loss: 0.6716 - acc: 0.6321 - val_loss: 0.5897 - val_acc: 0.7065\n",
      "Epoch 3/10\n",
      "1677/1677 [==============================] - 154s 92ms/step - loss: 0.6317 - acc: 0.6696 - val_loss: 0.5488 - val_acc: 0.7413\n",
      "Epoch 4/10\n",
      "1677/1677 [==============================] - 154s 92ms/step - loss: 0.6008 - acc: 0.6983 - val_loss: 0.5765 - val_acc: 0.7093\n",
      "Epoch 5/10\n",
      "1677/1677 [==============================] - 154s 92ms/step - loss: 0.5802 - acc: 0.7311 - val_loss: 0.5734 - val_acc: 0.7093\n",
      "Epoch 6/10\n",
      "1677/1677 [==============================] - 154s 92ms/step - loss: 0.5748 - acc: 0.7406 - val_loss: 0.5429 - val_acc: 0.7538\n",
      "Epoch 7/10\n",
      "1677/1677 [==============================] - 154s 92ms/step - loss: 0.5675 - acc: 0.7340 - val_loss: 0.4915 - val_acc: 0.8053\n",
      "Epoch 8/10\n",
      "1677/1677 [==============================] - 154s 92ms/step - loss: 0.5470 - acc: 0.7573 - val_loss: 0.4781 - val_acc: 0.8248\n",
      "Epoch 9/10\n",
      "1677/1677 [==============================] - 154s 92ms/step - loss: 0.5422 - acc: 0.7615 - val_loss: 0.4484 - val_acc: 0.8526\n",
      "Epoch 10/10\n",
      "1677/1677 [==============================] - 154s 92ms/step - loss: 0.5358 - acc: 0.7680 - val_loss: 0.4635 - val_acc: 0.8206\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.fit(images, encoded_target, epochs=10, batch_size=16, validation_split=0.3, verbose=1, shuffle=True)\n",
    "saved_model_relative_path: str = os.path.join(\"saved_models\", \"mha_vgg_faces.h5\")\n",
    "model.save(saved_model_relative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(images[0:500]).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1196., 1200.], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_target.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_augmentation_output = model.get_layer('concatenate_19').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_output = K.function([model.layers[0].input], [attention_augmentation_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECT = 1540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_output = get_output([images[SUBJECT].reshape((1,WIDTH,HEIGHT,3))])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_maps = np.mean(attention_output[0], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f57d56b9518>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(images[SUBJECT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.587063 , 13.8494215, 13.586394 , ..., 14.179725 , 14.539454 ,\n",
       "        15.779822 ],\n",
       "       [17.724117 , 16.329725 , 16.583895 , ..., 16.76062  , 16.655066 ,\n",
       "        19.603796 ],\n",
       "       [17.73637  , 16.34887  , 16.539625 , ..., 16.682531 , 16.844112 ,\n",
       "        19.544422 ],\n",
       "       ...,\n",
       "       [18.049322 , 16.806215 , 17.113243 , ..., 17.312819 , 17.342518 ,\n",
       "        19.773573 ],\n",
       "       [17.987164 , 17.018496 , 16.9551   , ..., 17.296083 , 17.44229  ,\n",
       "        19.874737 ],\n",
       "       [20.580105 , 21.10246  , 20.853943 , ..., 21.120197 , 21.152954 ,\n",
       "        29.906067 ]], dtype=float32)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_maps * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap is shape (60, 80, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[130, 255, 126],\n",
       "        [148,   0,   0],\n",
       "        [  0, 104, 255],\n",
       "        ...,\n",
       "        [164,   0,   0],\n",
       "        [200,   0,   0],\n",
       "        [  0,  84, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_heatmap(cam: np.ndarray)-> np.ndarray:\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET)\n",
    "    heatmap[np.where(cam < 20)] = 0\n",
    "    print(f\"Heatmap is shape {heatmap.shape}\")\n",
    "    return heatmap\n",
    "\n",
    "heatmap = make_heatmap(attention_maps * 0.2)\n",
    "heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f57d561f320>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_image = heatmap + images[SUBJECT]\n",
    "plt.imshow(np.array(final_image,np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 80)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_maps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
